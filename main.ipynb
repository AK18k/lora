{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AK18k/lora/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19mBVBKOU8ul",
        "outputId": "5f421277-f560-44cd-f9b8-c5ab4339d970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lora'...\n",
            "remote: Enumerating objects: 1405, done.\u001b[K\n",
            "remote: Counting objects: 100% (1405/1405), done.\u001b[K\n",
            "remote: Compressing objects: 100% (999/999), done.\u001b[K\n",
            "remote: Total 1405 (delta 389), reused 1377 (delta 371), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1405/1405), 23.87 MiB | 16.50 MiB/s, done.\n",
            "Resolving deltas: 100% (389/389), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AK18k/lora"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install progress"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGTMRSDrVdwA",
        "outputId": "87cb4b81-0c75-49ed-f1a3-5923c0dad8fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting progress\n",
            "  Downloading progress-1.6.tar.gz (7.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: progress\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progress: filename=progress-1.6-py3-none-any.whl size=9611 sha256=10a4294f0d7e5d71323e9331172ed093d121b977e4bb8b7fb266b2f6531f68b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/68/5f/c339b20a41659d856c93ccdce6a33095493eb82c3964aac5a1\n",
            "Successfully built progress\n",
            "Installing collected packages: progress\n",
            "Successfully installed progress-1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cd ./lora/examples/NLG\n",
        "# !ls '*.sh'\n",
        "!bash ./lora/examples/NLG/download_pretrained_checkpoints.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aI_0ZMPVrux",
        "outputId": "5eeff236-b231-418c-97d6-ca7956f0cd57"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading pretrained model checkpoints...\n",
            "--2023-06-03 15:08:14--  https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.128.136, 52.216.211.248, 52.216.109.133, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.128.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 548118077 (523M) [application/octet-stream]\n",
            "Saving to: ‘gpt2-pytorch_model.bin’\n",
            "\n",
            "gpt2-pytorch_model. 100%[===================>] 522.73M  33.2MB/s    in 17s     \n",
            "\n",
            "2023-06-03 15:08:31 (31.4 MB/s) - ‘gpt2-pytorch_model.bin’ saved [548118077/548118077]\n",
            "\n",
            "--2023-06-03 15:08:31--  https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-pytorch_model.bin\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.138.101, 52.217.233.176, 52.217.75.150, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.138.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520013706 (1.4G) [application/octet-stream]\n",
            "Saving to: ‘gpt2-medium-pytorch_model.bin’\n",
            "\n",
            "gpt2-medium-pytorch 100%[===================>]   1.42G  33.6MB/s    in 44s     \n",
            "\n",
            "2023-06-03 15:09:16 (33.2 MB/s) - ‘gpt2-medium-pytorch_model.bin’ saved [1520013706/1520013706]\n",
            "\n",
            "--2023-06-03 15:09:16--  https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-large-pytorch_model.bin\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.202.80, 54.231.162.176, 52.217.139.208, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.202.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3247202234 (3.0G) [application/octet-stream]\n",
            "Saving to: ‘gpt2-large-pytorch_model.bin’\n",
            "\n",
            "gpt2-large-pytorch_ 100%[===================>]   3.02G  33.9MB/s    in 94s     \n",
            "\n",
            "2023-06-03 15:10:50 (33.1 MB/s) - ‘gpt2-large-pytorch_model.bin’ saved [3247202234/3247202234]\n",
            "\n",
            "script complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash ./lora/examples/NLG/create_datasets.sh"
      ],
      "metadata": {
        "id": "EuLfqW_PYwlz",
        "outputId": "3af487de-c42f-4575-8d03-526c35e275cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating e2e datasets...\n",
            "train...\n",
            "test...\n",
            "valid...\n",
            "creating webnlg datasets...\n",
            "train...\n",
            "cate Airport 1090\n",
            "cate Astronaut 530\n",
            "cate Building 972\n",
            "cate City 243\n",
            "cate ComicsCharacter 285\n",
            "cate Food 1424\n",
            "cate Monument 267\n",
            "cate SportsTeam 786\n",
            "cate University 406\n",
            "cate WrittenWork 937\n",
            "test...\n",
            "cate Airport 136\n",
            "cate Monument 33\n",
            "cate Building 120\n",
            "cate WrittenWork 116\n",
            "cate SportsTeam 98\n",
            "cate University 51\n",
            "cate Astronaut 66\n",
            "cate ComicsCharacter 35\n",
            "cate City 139\n",
            "cate Food 177\n",
            "cate Politician 209\n",
            "cate MeanOfTransportation 198\n",
            "cate Athlete 159\n",
            "cate Artist 213\n",
            "cate CelestialBody 112\n",
            "valid...\n",
            "cate Airport 136\n",
            "cate Astronaut 67\n",
            "cate Building 123\n",
            "cate City 31\n",
            "cate ComicsCharacter 37\n",
            "cate Food 178\n",
            "cate Monument 32\n",
            "cate SportsTeam 99\n",
            "cate University 51\n",
            "cate WrittenWork 118\n",
            "creating dart datasets...\n",
            "train...\n",
            "unique source is 30526\n",
            "test...\n",
            "unique source is 6959\n",
            "valid...\n",
            "unique source is 2768\n",
            "script complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /content/lora/examples/NLG/eval/download_evalscript.sh\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4rEoOZvysmM",
        "outputId": "5cc5cc17-ee9d-4d89-ea71-aa71d5410b1b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "installing evaluation dependencies\n",
            "downloading e2e-metrics...\n",
            "Cloning into 'e2e'...\n",
            "remote: Enumerating objects: 909, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 909 (delta 0), reused 1 (delta 0), pack-reused 906\u001b[K\n",
            "Receiving objects: 100% (909/909), 106.78 MiB | 14.45 MiB/s, done.\n",
            "Resolving deltas: 100% (492/492), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r e2e/requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r e2e/requirements.txt (line 2)) (0.19.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from -r e2e/requirements.txt (line 3)) (0.18.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r e2e/requirements.txt (line 1)) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r e2e/requirements.txt (line 1)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r e2e/requirements.txt (line 1)) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r e2e/requirements.txt (line 1)) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r e2e/requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r e2e/requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r e2e/requirements.txt (line 1)) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r e2e/requirements.txt (line 1)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r e2e/requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r e2e/requirements.txt (line 2)) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r e2e/requirements.txt (line 2)) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r e2e/requirements.txt (line 2)) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r e2e/requirements.txt (line 2)) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r e2e/requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->-r e2e/requirements.txt (line 1)) (1.16.0)\n",
            "downloading GenerationEval for webnlg and dart...\n",
            "Cloning into 'GenerationEval'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 82 (delta 36), reused 51 (delta 15), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (82/82), 221.17 KiB | 5.27 MiB/s, done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nltk==3.5 (from -r requirements.txt (line 1))\n",
            "  Downloading nltk-3.5.zip (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyter3==0.3 (from -r requirements.txt (line 2))\n",
            "  Downloading pyter3-0.3-py3-none-any.whl (4.1 kB)\n",
            "Collecting razdel==0.5.0 (from -r requirements.txt (line 3))\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Collecting tabulate==0.8.7 (from -r requirements.txt (line 4))\n",
            "  Downloading tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
            "Collecting bert-score==0.3.5 (from -r requirements.txt (line 5))\n",
            "  Downloading bert_score-0.3.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.5->-r requirements.txt (line 1)) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.5->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from nltk==3.5->-r requirements.txt (line 1)) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk==3.5->-r requirements.txt (line 1)) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.5->-r requirements.txt (line 5)) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.5->-r requirements.txt (line 5)) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.5->-r requirements.txt (line 5)) (1.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.5->-r requirements.txt (line 5)) (2.27.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.5->-r requirements.txt (line 5)) (3.7.1)\n",
            "Collecting transformers>=3.0.0 (from bert-score==0.3.5->-r requirements.txt (line 5))\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score==0.3.5->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score==0.3.5->-r requirements.txt (line 5)) (2022.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.5->-r requirements.txt (line 5)) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.5->-r requirements.txt (line 5)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.5->-r requirements.txt (line 5)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.5->-r requirements.txt (line 5)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.5->-r requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.5->-r requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->bert-score==0.3.5->-r requirements.txt (line 5)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->bert-score==0.3.5->-r requirements.txt (line 5)) (16.0.5)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers>=3.0.0->bert-score==0.3.5->-r requirements.txt (line 5))\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score==0.3.5->-r requirements.txt (line 5)) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score==0.3.5->-r requirements.txt (line 5)) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=3.0.0->bert-score==0.3.5->-r requirements.txt (line 5))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.5->-r requirements.txt (line 5)) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.5->-r requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.5->-r requirements.txt (line 5)) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.5->-r requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.5->-r requirements.txt (line 5)) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.5->-r requirements.txt (line 5)) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score==0.3.5->-r requirements.txt (line 5)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score==0.3.5->-r requirements.txt (line 5)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score==0.3.5->-r requirements.txt (line 5)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score==0.3.5->-r requirements.txt (line 5)) (3.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=3.0.0->bert-score==0.3.5->-r requirements.txt (line 5)) (2023.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert-score==0.3.5->-r requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score==0.3.5->-r requirements.txt (line 5)) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert-score==0.3.5->-r requirements.txt (line 5)) (1.3.0)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434675 sha256=0f756392734ead3f6b117c9f5bb5f95b11840d7bd62ee5af4d9ee008daa2ef04\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/ab/82/f9667f6f884d272670a15382599a9c753a1dfdc83f7412e37d\n",
            "Successfully built nltk\n",
            "Installing collected packages: tokenizers, tabulate, razdel, pyter3, nltk, huggingface-hub, transformers, bert-score\n",
            "  Attempting uninstall: tabulate\n",
            "    Found existing installation: tabulate 0.8.10\n",
            "    Uninstalling tabulate-0.8.10:\n",
            "      Successfully uninstalled tabulate-0.8.10\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "Successfully installed bert-score-0.3.5 huggingface-hub-0.15.1 nltk-3.5 pyter3-0.3 razdel-0.5.0 tabulate-0.8.7 tokenizers-0.13.3 transformers-4.29.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Cloning into 'bleurt'...\n",
            "remote: Enumerating objects: 134, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 134 (delta 0), reused 17 (delta 0), pack-reused 116\u001b[K\n",
            "Receiving objects: 100% (134/134), 31.28 MiB | 7.59 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/lora/examples/NLG/eval/GenerationEval/bleurt\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (1.10.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (2.12.0)\n",
            "Requirement already satisfied: tf-slim>=1.1 in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (1.1.0)\n",
            "Collecting sentencepiece (from BLEURT==0.0.2)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim>=1.1->BLEURT==0.0.2) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->BLEURT==0.0.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->BLEURT==0.0.2) (2022.7.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->BLEURT==0.0.2) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow->BLEURT==0.0.2) (0.1.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->BLEURT==0.0.2) (3.2.2)\n",
            "Building wheels for collected packages: BLEURT\n",
            "  Building wheel for BLEURT (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for BLEURT: filename=BLEURT-0.0.2-py3-none-any.whl size=16456764 sha256=bd8c9344b36003fc83b002f2306234f746c1003ba6943b3fe84aa101572c50cf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d_y9o7k7/wheels/c1/e2/57/89889ede6c030dbd8e5d2fb4c865fa9aa3d0883fc68a3aa6aa\n",
            "Successfully built BLEURT\n",
            "Installing collected packages: sentencepiece, BLEURT\n",
            "Successfully installed BLEURT-0.0.2 sentencepiece-0.1.99\n",
            "--2023-06-03 15:13:33--  https://storage.googleapis.com/bleurt-oss/bleurt-base-128.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.119.128, 108.177.126.128, 108.177.127.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.119.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 405489453 (387M) [application/zip]\n",
            "Saving to: ‘bleurt-base-128.zip’\n",
            "\n",
            "bleurt-base-128.zip 100%[===================>] 386.70M  37.3MB/s    in 12s     \n",
            "\n",
            "2023-06-03 15:13:45 (33.0 MB/s) - ‘bleurt-base-128.zip’ saved [405489453/405489453]\n",
            "\n",
            "Archive:  bleurt-base-128.zip\n",
            "   creating: bleurt-base-128/\n",
            "  inflating: bleurt-base-128/vocab.txt  \n",
            "  inflating: bleurt-base-128/bert_config.json  \n",
            "   creating: bleurt-base-128/variables/\n",
            "  inflating: bleurt-base-128/variables/variables.index  \n",
            "  inflating: bleurt-base-128/variables/variables.data-00000-of-00001  \n",
            "  inflating: bleurt-base-128/bleurt_config.json  \n",
            "  inflating: bleurt-base-128/saved_model.pb  \n",
            "--2023-06-03 15:13:49--  https://www.cs.cmu.edu/~alavie/METEOR/download/meteor-1.5.tar.gz\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 223646468 (213M) [application/x-gzip]\n",
            "Saving to: ‘meteor-1.5.tar.gz’\n",
            "\n",
            "meteor-1.5.tar.gz   100%[===================>] 213.29M  1.36MB/s    in 3m 27s  \n",
            "\n",
            "2023-06-03 15:17:17 (1.03 MB/s) - ‘meteor-1.5.tar.gz’ saved [223646468/223646468]\n",
            "\n",
            "meteor-1.5/\n",
            "meteor-1.5/data/\n",
            "meteor-1.5/data/paraphrase-es.gz\n",
            "meteor-1.5/data/paraphrase-cz.gz\n",
            "meteor-1.5/data/paraphrase-fr.gz\n",
            "meteor-1.5/data/paraphrase-en.gz\n",
            "meteor-1.5/data/paraphrase-de.gz\n",
            "meteor-1.5/data/paraphrase-ru.gz\n",
            "meteor-1.5/xray/\n",
            "meteor-1.5/xray/visualize_alignments.py\n",
            "meteor-1.5/xray/template/\n",
            "meteor-1.5/xray/template/score.tex\n",
            "meteor-1.5/xray/xray.py\n",
            "meteor-1.5/xray/MeteorAlignment.py\n",
            "meteor-1.5/xray/Generation.py\n",
            "meteor-1.5/scripts/\n",
            "meteor-1.5/scripts/sgmlize.py\n",
            "meteor-1.5/scripts/meteor_shower.py\n",
            "meteor-1.5/scripts/unroll_wmt_ranks.py\n",
            "meteor-1.5/scripts/meteorToMosesAlign.py\n",
            "meteor-1.5/scripts/delete_stray_matches.py\n",
            "meteor-1.5/scripts/bleu.py\n",
            "meteor-1.5/scripts/wmt_bleu.py\n",
            "meteor-1.5/scripts/tc_train_set.py\n",
            "meteor-1.5/scripts/wmt_ter.py\n",
            "meteor-1.5/scripts/freq.py\n",
            "meteor-1.5/scripts/filter_merge_rank_set.py\n",
            "meteor-1.5/scripts/wmt-eval.sh\n",
            "meteor-1.5/scripts/new_language.py\n",
            "meteor-1.5/scripts/tercom-0.8.0.jar\n",
            "meteor-1.5/scripts/ter.py\n",
            "meteor-1.5/scripts/agg.py\n",
            "meteor-1.5/scripts/build_wordnet_files.py\n",
            "meteor-1.5/scripts/combine_segcor_trainset.py\n",
            "meteor-1.5/scripts/rankconsist.py\n",
            "meteor-1.5/scripts/wmt_fmt.py\n",
            "meteor-1.5/scripts/mteval-v13m.pl\n",
            "meteor-1.5/README.html\n",
            "meteor-1.5/INSTALL\n",
            "meteor-1.5/resources/\n",
            "meteor-1.5/resources/stem/\n",
            "meteor-1.5/resources/stem/arabic-buckwalter-reduced.gz\n",
            "meteor-1.5/resources/nonbreaking/\n",
            "meteor-1.5/resources/nonbreaking/english.prefixes\n",
            "meteor-1.5/resources/nonbreaking/french.prefixes\n",
            "meteor-1.5/resources/nonbreaking/russian.prefixes\n",
            "meteor-1.5/resources/nonbreaking/german.prefixes\n",
            "meteor-1.5/resources/nonbreaking/spanish.prefixes\n",
            "meteor-1.5/resources/nonbreaking/czech.prefixes\n",
            "meteor-1.5/resources/synonym/\n",
            "meteor-1.5/resources/synonym/COPYING.WORDNET\n",
            "meteor-1.5/resources/synonym/english.synsets\n",
            "meteor-1.5/resources/synonym/english.exceptions\n",
            "meteor-1.5/resources/synonym/english.relations\n",
            "meteor-1.5/resources/function/\n",
            "meteor-1.5/resources/function/french.words\n",
            "meteor-1.5/resources/function/russian.words\n",
            "meteor-1.5/resources/function/romanian.words\n",
            "meteor-1.5/resources/function/dutch.words\n",
            "meteor-1.5/resources/function/arabic-buckwalter-reduced.words\n",
            "meteor-1.5/resources/function/portuguese.words\n",
            "meteor-1.5/resources/function/turkish.words\n",
            "meteor-1.5/resources/function/norwegian.words\n",
            "meteor-1.5/resources/function/danish.words\n",
            "meteor-1.5/resources/function/swedish.words\n",
            "meteor-1.5/resources/function/other.words\n",
            "meteor-1.5/resources/function/italian.words\n",
            "meteor-1.5/resources/function/english.words\n",
            "meteor-1.5/resources/function/spanish.words\n",
            "meteor-1.5/resources/function/czech.words\n",
            "meteor-1.5/resources/function/hungarian.words\n",
            "meteor-1.5/resources/function/german.words\n",
            "meteor-1.5/resources/function/finnish.words\n",
            "meteor-1.5/COPYING\n",
            "meteor-1.5/mt-diff/\n",
            "meteor-1.5/mt-diff/mt-diff.py\n",
            "meteor-1.5/mt-diff/files/\n",
            "meteor-1.5/mt-diff/files/mteval-v13m.pl\n",
            "meteor-1.5/example/\n",
            "meteor-1.5/example/xray/\n",
            "meteor-1.5/example/xray/reference\n",
            "meteor-1.5/example/xray/system1.hyp\n",
            "meteor-1.5/example/xray/system2.hyp\n",
            "meteor-1.5/example/tune/\n",
            "meteor-1.5/example/tune/example.score.in\n",
            "meteor-1.5/example/tune/example.eval.in\n",
            "meteor-1.5/example/tune/example.score.out\n",
            "meteor-1.5/example/tune/example.eval.out\n",
            "meteor-1.5/example/meteor-seg.scr\n",
            "meteor-1.5/example/meteor-sys.scr\n",
            "meteor-1.5/example/train/\n",
            "meteor-1.5/example/train/fr-en.sys2\n",
            "meteor-1.5/example/train/fr-en.sys1\n",
            "meteor-1.5/example/train/fr-en.ref\n",
            "meteor-1.5/example/train/fr-en.rank\n",
            "meteor-1.5/example/ref.sgm\n",
            "meteor-1.5/example/test.sgm\n",
            "meteor-1.5/example/meteor-doc.scr\n",
            "meteor-1.5/build.xml\n",
            "meteor-1.5/src/\n",
            "meteor-1.5/src/Trainer.java\n",
            "meteor-1.5/src/FilterParaphrase.java\n",
            "meteor-1.5/src/Meteor.java\n",
            "meteor-1.5/src/SGMtoPlaintext.java\n",
            "meteor-1.5/src/org/\n",
            "meteor-1.5/src/org/tartarus/\n",
            "meteor-1.5/src/org/tartarus/snowball/\n",
            "meteor-1.5/src/org/tartarus/snowball/Among.java\n",
            "meteor-1.5/src/org/tartarus/snowball/SnowballStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/germanStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/russianStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/swedishStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/hungarianStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/turkishStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/romanianStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/dutchStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/danishStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/portugueseStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/englishStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/finnishStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/porterStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/italianStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/norwegianStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/spanishStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/frenchStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/SnowballProgram.java\n",
            "meteor-1.5/src/Parex.java\n",
            "meteor-1.5/src/edu/\n",
            "meteor-1.5/src/edu/cmu/\n",
            "meteor-1.5/src/edu/cmu/meteor/\n",
            "meteor-1.5/src/edu/cmu/meteor/scorer/\n",
            "meteor-1.5/src/edu/cmu/meteor/scorer/MeteorScorer.java\n",
            "meteor-1.5/src/edu/cmu/meteor/scorer/MeteorStats.java\n",
            "meteor-1.5/src/edu/cmu/meteor/scorer/MeteorConfiguration.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/ParaphraseTransducer.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/SynonymDictionary.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/ExactMatcher.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/ParaphraseMatcher.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/Alignment.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/Match.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/LookupTableStemmer.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/Stage.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/SnowballStemmerWrapper.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/StemMatcher.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/Aligner.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/PartialAlignment.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/Stemmer.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/SynonymMatcher.java\n",
            "meteor-1.5/src/edu/cmu/meteor/util/\n",
            "meteor-1.5/src/edu/cmu/meteor/util/Constants.java\n",
            "meteor-1.5/src/edu/cmu/meteor/util/Normalizer.java\n",
            "meteor-1.5/src/edu/cmu/meteor/util/SGMData.java\n",
            "meteor-1.5/src/edu/cmu/parex/\n",
            "meteor-1.5/src/edu/cmu/parex/PhraseTable.java\n",
            "meteor-1.5/src/edu/cmu/parex/ParaphraseExtractor.java\n",
            "meteor-1.5/src/edu/cmu/parex/Paraphrase.java\n",
            "meteor-1.5/src/Matcher.java\n",
            "meteor-1.5/src/Stemmer.java\n",
            "meteor-1.5/meteor-1.5.jar\n",
            "script complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/lora/')\n",
        "sys.path.append('/content/lora/examples/NLG/src')"
      ],
      "metadata": {
        "id": "D8CkfRkA5HOp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!torchrun --nproc_per_node=1 /content/lora/examples/NLG/src/gpt2_ft.py \\\n",
        "    --train_data /content/lora/examples/NLG/data/e2e/train.jsonl \\\n",
        "    --valid_data /content/lora/examples/NLG/data/e2e/valid.jsonl \\\n",
        "    --train_batch_size 8 \\\n",
        "    --grad_acc 1 \\\n",
        "    --valid_batch_size 4 \\\n",
        "    --seq_len 512 \\\n",
        "    --model_card gpt2.md \\\n",
        "    --init_checkpoint ./pretrained_checkpoints/gpt2-medium-pytorch_model.bin \\\n",
        "    --platform local \\\n",
        "    --clip 0.0 \\\n",
        "    --lr 0.0002 \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --correct_bias \\\n",
        "    --adam_beta2 0.999 \\\n",
        "    --scheduler linear \\\n",
        "    --warmup_step 500 \\\n",
        "    --max_epoch 5 \\\n",
        "    --save_interval 1000 \\\n",
        "    --lora_dim 4 \\\n",
        "    --lora_alpha 32 \\\n",
        "    --lora_dropout 0.1 \\\n",
        "    --label_smooth 0.1 \\\n",
        "    --work_dir ./trained_models/GPT2_M/e2e \\\n",
        "    --random_seed 110"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF8p0wGr49nU",
        "outputId": "bc467c3c-ae4a-4e6d-be5f-c2bcced23fc8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "myrank: 0 local_rank: 0 device_count: 1 world_size: 1\n",
            "====================================================================================================\n",
            "        - platform : local\n",
            "        - local_rank : 0\n",
            "        - rank : 0\n",
            "        - device : cuda:0\n",
            "        - world_size : 1\n",
            "        - random_seed : 110\n",
            "        - lr : 0.0002\n",
            "        - weight_decay : 0.01\n",
            "        - correct_bias : True\n",
            "        - adam_epislon : 1e-06\n",
            "        - no_decay_bias : False\n",
            "        - adam_beta1 : 0.9\n",
            "        - adam_beta2 : 0.999\n",
            "        - scheduler : linear\n",
            "        - max_step : None\n",
            "        - max_epoch : 5\n",
            "        - warmup_step : 500\n",
            "        - i_steps : 0\n",
            "        - i_lrs : 0.00025\n",
            "        - train_data : ./data/e2e/train.jsonl\n",
            "        - valid_data : ./data/e2e/valid.jsonl\n",
            "        - train_batch_size : 8\n",
            "        - valid_batch_size : 4\n",
            "        - grad_acc : 1\n",
            "        - clip : 0.0\n",
            "        - seq_len : 512\n",
            "        - model_card : gpt2.md\n",
            "        - init_checkpoint : ./pretrained_checkpoints/gpt2-medium-pytorch_model.bin\n",
            "        - fp16 : False\n",
            "        - log_interval : 100\n",
            "        - eval_interval : 2000\n",
            "        - save_interval : 1000\n",
            "        - work_dir : ./trained_models/GPT2_M/e2e\n",
            "        - lora_dim : 4\n",
            "        - lora_alpha : 32\n",
            "        - obj : clm\n",
            "        - lora_dropout : 0.1\n",
            "        - label_smooth : 0.1\n",
            "        - roll_interval : -1\n",
            "        - roll_lr : 1e-05\n",
            "        - roll_step : 100\n",
            "        - eval_epoch : 1\n",
            "        - dist : <module 'torch.distributed' from '/usr/local/lib/python3.10/dist-packages/torch/distributed/__init__.py'>\n",
            "====================================================================================================\n",
            "Experiment dir : ./trained_models/GPT2_M/e2e\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/lora/examples/NLG/src/gpt2_ft.py\", line 283, in <module>\n",
            "    train_data = FT_Dataset(\n",
            "  File \"/content/lora/examples/NLG/src/data_utils.py\", line 203, in __init__\n",
            "    self.ft_samples = self.read_ft_file(ft_file)\n",
            "  File \"/content/lora/examples/NLG/src/data_utils.py\", line 263, in read_ft_file\n",
            "    with open(ft_file, 'r') as reader:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: './data/e2e/train.jsonl'\n",
            "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 3718) of binary: /usr/bin/python3\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/torchrun\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 346, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 794, in main\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 785, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 134, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 250, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "/content/lora/examples/NLG/src/gpt2_ft.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2023-06-03_15:17:36\n",
            "  host      : e3ac5c6d11c0\n",
            "  rank      : 0 (local_rank: 0)\n",
            "  exitcode  : 1 (pid: 3718)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}